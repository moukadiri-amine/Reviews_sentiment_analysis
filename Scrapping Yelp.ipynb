{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#First-steps\" data-toc-modified-id=\"First-steps-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>First steps</a></span></li><li><span><a href=\"#Web-Scraping-functions\" data-toc-modified-id=\"Web-Scraping-functions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Web Scraping functions</a></span></li><li><span><a href=\"#Running-Scraping\" data-toc-modified-id=\"Running-Scraping-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Running Scraping</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae95cf7b1ce04824b6665b927ad2ec36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method tqdm.pandas of <class 'tqdm._tqdm_notebook.tqdm_notebook'>>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests as rq\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm_notebook().pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First steps\n",
    "Creating a BeautifulSoup object with the webpage we want, here it's the default page when we specify restaurants in New York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = rq.get('https://www.yelp.com/search?find_desc=Restaurants&find_loc=New+York,+NY,+%C3%89tats-Unis').text\n",
    "soup = BeautifulSoup(html,\"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An empty DataFrame that will store all of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get Name and Address of each restaurants, and call the get_reviews() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_restaurants(restaurants, entries):\n",
    "    \n",
    "    new_restaurants1 = pd.DataFrame()\n",
    "    for s,i in tqdm(zip(entries,range(len(entries)))):\n",
    "        try:      \n",
    "            link = s.find('a', attrs={'class':'biz-name js-analytics-click'})['href']\n",
    "            reviews = get_reviews(link)\n",
    "            for t in range(reviews.shape[0]):\n",
    "                reviews.loc[t,'name']=s.find('a',attrs={'class':'biz-name'}).get_text().strip()\n",
    "                reviews.loc[t,'adress']=s.find('address').contents[0].strip()\n",
    "            new_restaurants1 = pd.concat([new_restaurants1,reviews],ignore_index=True)\n",
    "        except:\n",
    "            pass\n",
    "    restaurants = pd.concat([restaurants,new_restaurants1],ignore_index=True)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    return restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get the reviews from a restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(link):\n",
    "    \n",
    "    text = []\n",
    "    stars= []\n",
    "    html_link = rq.get('https://www.yelp.com'+link).text\n",
    "    soup_link = BeautifulSoup(html_link,\"lxml\")\n",
    "    \n",
    "    number_of_pages = soup_link.find('div', attrs={'class':'page-of-pages arrange_unit arrange_unit--fill'}).get_text().strip()\n",
    "    number_of_pages = int(number_of_pages.split('of ')[1])\n",
    "    \n",
    "    if(number_of_pages<2):#get the restaurants with a min of 20 reviews\n",
    "        return None\n",
    "    if(number_of_pages>7): #limit the number of reviews to 140\n",
    "        number_of_pages = 7\n",
    "\n",
    "    for i in range(number_of_pages):\n",
    "        reviews_list = soup_link.find('ul', attrs={'class':'ylist ylist-bordered reviews'})\n",
    "        for s,n in zip(reviews_list,range(len(reviews_list))):\n",
    "            try:\n",
    "                large_star = s.find('div',attrs={'biz-rating biz-rating-large clearfix'})\n",
    "                stars.append(large_star.find('img')['alt'][:3])\n",
    "                text.append(s.find('p').get_text(strip=True, separator=' '))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        if (i!=number_of_pages-1):\n",
    "            link = soup_link.find('a', attrs={'u-decoration-none next pagination-links_anchor'})['href']\n",
    "            html_link = rq.get(link).text\n",
    "            soup_link = BeautifulSoup(html_link,\"lxml\")\n",
    "        time.sleep(5)\n",
    "        \n",
    "    reviews = pd.DataFrame({'review':text,'stars':stars})\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "149it [00:00, 4918.01it/s]\n"
     ]
    }
   ],
   "source": [
    "entries = soup.find_all('div',attrs={'class':'lemon--div__373c0__1mboc border-color--default__373c0__2oFDT'})\n",
    "restaurants = fill_restaurants(restaurants, entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then looping through the pages (there are 33 pages for New York because page 34 doesn't work).\n",
    "\n",
    "Yelp have blocked me after 1h30 hours (including previous cell) which retrieved me 13 000 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "number_of_pages = 1 #out of 33\n",
    "for i in range(number_of_pages):\n",
    "    next_page_link = soup.find('a',attrs={'class':'lemon--a__373c0__IEZFH link__373c0__29943 link-color--blue-dark__373c0__1mhJo link-size--default__373c0__1skgq'})['href']\n",
    "    html = rq.get('https://www.yelp.com'+next_page_link).text\n",
    "    soup = BeautifulSoup(html,\"lxml\")\n",
    "    entries = soup.find_all('div',attrs={'class':'search-result'})\n",
    "    restaurants = fill_restaurants(restaurants,entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants.to_csv('restaurants_ny.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
